# Horizontal Pod Autoscaler for AI-PAL application
# Automatically scales pods based on CPU/Memory usage

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ai-pal-hpa
  namespace: ai-pal
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ai-pal-app

  minReplicas: 3
  maxReplicas: 10

  metrics:
  # CPU-based scaling
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # Scale up when CPU > 70%

  # Memory-based scaling
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80  # Scale up when memory > 80%

  # Custom metrics (if using Prometheus Adapter)
  # - type: Pods
  #   pods:
  #     metric:
  #       name: http_requests_per_second
  #     target:
  #       type: AverageValue
  #       averageValue: "1000"

  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50  # Scale up by 50% at a time
        periodSeconds: 60
      - type: Pods
        value: 2  # Or add 2 pods at a time
        periodSeconds: 60
      selectPolicy: Max  # Use the policy that scales fastest

    scaleDown:
      stabilizationWindowSeconds: 300  # Wait 5 minutes before scaling down
      policies:
      - type: Percent
        value: 25  # Scale down by 25% at a time
        periodSeconds: 60
      - type: Pods
        value: 1  # Or remove 1 pod at a time
        periodSeconds: 60
      selectPolicy: Min  # Use the policy that scales slowest
